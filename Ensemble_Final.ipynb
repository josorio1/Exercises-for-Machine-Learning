{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods. Exercises\n",
    "\n",
    "\n",
    "In this section we have only two exercise:\n",
    "\n",
    "1. Find the best three classifier in the stacking method using the classifiers from scikit-learn package.\n",
    "\n",
    "2. Build arcing arc-x4 method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data_set\n",
    "%store -r labels\n",
    "%store -r test_data_set\n",
    "%store -r test_labels\n",
    "%store -r unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Find the best three classifier in the stacking method\n",
    "\n",
    "Please use the following classifiers:\n",
    "\n",
    "* Linear regression,\n",
    "* Nearest Neighbors,\n",
    "* Linear SVM,\n",
    "* Decision Tree,\n",
    "* Naive Bayes,\n",
    "* QDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifiers():\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(data_set, labels)\n",
    "    \n",
    "    neighbors = KNeighborsClassifier()\n",
    "    neighbors.fit(data_set, labels)\n",
    "\n",
    "    svm = SVC()\n",
    "    svm.fit(data_set,labels)\n",
    "    \n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(data_set,labels)\n",
    "    \n",
    "    naive_bayes = GaussianNB()\n",
    "    naive_bayes.fit(data_set, labels)\n",
    "    \n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    qda.fit(data_set, labels)\n",
    "\n",
    "\n",
    "    return linear_regression, neighbors, svm, decision_tree, naive_bayes, qda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to add another variable into build_stacked_classifier called *stacker*, which is the classifier we will use to stack. After we do this, we can run the function inside a for loop that goes over all the six possible classifiers. At the same time, we have the variable *classifier*, which will be three selected classifiers. In order to find all the possibilities, we can use *combinations* from itertools, and write another loop inside the first one that runs all over the possible trios.\n",
    "\n",
    "Also, you told us that there is at least one combination that gives accuracy of 1, so I will add some lines that would stop the loops if we find such combination (I ran it without these lines to check if there are more, and there are plenty).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stacked_classifier(classifiers,stacker):\n",
    "    output = []\n",
    "    for classifier in classifiers:\n",
    "        output.append(classifier.predict(data_set))\n",
    "    output = np.array(output).reshape((130,3))\n",
    "    \n",
    "    # stacked classifier part:\n",
    "    stacked_classifier = stacker\n",
    "    stacked_classifier.fit(output.reshape((130,3)), labels.reshape((130,)))\n",
    "    test_set = []\n",
    "    for classifier in classifiers:\n",
    "        test_set.append(classifier.predict(test_data_set))\n",
    "    test_set = np.array(test_set).reshape((len(test_set[0]),3))\n",
    "    predicted = stacked_classifier.predict(test_set)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy 1.0\n",
      "The best three classifiers are: (LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform'), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False))\n",
      "With the stacker: GaussianNB(priors=None, var_smoothing=1e-09)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "classifiers = build_classifiers()\n",
    "stackers = [ LinearRegression(), KNeighborsClassifier(), SVC(), DecisionTreeClassifier(),\n",
    "            GaussianNB(), QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "classifier_combinations= list(combinations(classifiers,r=3))\n",
    "\n",
    "accuracy_aux = 0\n",
    "stop = False\n",
    "for stacker in stackers: \n",
    " for i in range(len(classifier_combinations)):      \n",
    "       predicted = build_stacked_classifier(classifier_combinations[i],stacker)\n",
    "       accuracy = accuracy_score(test_labels, [ int(x) for x in predicted ]) # Only necessary for LinearRegression\n",
    "       if accuracy>accuracy_aux:\n",
    "        accuracy_aux = accuracy\n",
    "        best_classifier = [classifier_combinations[i],stacker]\n",
    "       if accuracy_aux == 1:\n",
    "        stop = True\n",
    "        break\n",
    " if stop:\n",
    "    break\n",
    "print(\"The highest accuracy\", accuracy_aux)\n",
    "print(\"The best three classifiers are:\", best_classifier[0])\n",
    "print(\"With the stacker:\", best_classifier[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: \n",
    "\n",
    "Use the boosting method and change the code to fullfilt the following requirements:\n",
    "\n",
    "* the weights should be calculated as:\n",
    "$w_{n}^{(t+1)}=\\frac{1+ I(y_{n}\\neq h_{t}(x_{n})}{\\sum_{i=1}^{N}1+I(y_{n}\\neq h_{t}(x_{n})}$,\n",
    "* the prediction is done with a voting method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# prepare data set\n",
    "\n",
    "def generate_data(sample_number, feature_number, label_number):\n",
    "    data_set = np.random.random_sample((sample_number, feature_number))\n",
    "    labels = np.random.choice(label_number, sample_number)\n",
    "    return data_set, labels\n",
    "\n",
    "labels = 2\n",
    "dimension = 2\n",
    "test_set_size = 1000\n",
    "train_set_size = 5000\n",
    "train_set, train_labels = generate_data(train_set_size, dimension, labels)\n",
    "test_set, test_labels = generate_data(test_set_size, dimension, labels)\n",
    "\n",
    "# init weights\n",
    "number_of_iterations = 10\n",
    "weights = np.ones((test_set_size,)) / test_set_size\n",
    "\n",
    "\n",
    "def train_model(classifier, weights):\n",
    "    return classifier.fit(X=test_set, y=test_labels, sample_weight=weights)\n",
    "\n",
    "\n",
    "def calculate_accuracy_vector(predicted, labels):\n",
    "    result = []\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == labels[i]:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    return result\n",
    "\n",
    "def calculate_error(model):\n",
    "    predicted = model.predict(test_set)\n",
    "    I=calculate_accuracy_vector(predicted, test_labels)\n",
    "    Z=np.sum(I)\n",
    "    return (1+Z)/1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the two functions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_weights(model):\n",
    "    new_weights = np.add(calculate_accuracy_vector(model.predict(test_set), test_labels),[1 for i in range(len(test_labels))])\n",
    "    print(len(new_weights))\n",
    "    sum_I = np.sum(new_weights)\n",
    "    return new_weights/sum_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "[0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566\n",
      " 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132\n",
      " 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566\n",
      " 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566\n",
      " 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0006566 0.0006566 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132\n",
      " 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132\n",
      " 0.0006566 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0006566\n",
      " 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132 0.0013132\n",
      " 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566\n",
      " 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0006566 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0013132 0.0013132\n",
      " 0.0013132 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0013132\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566 0.0013132\n",
      " 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566 0.0006566\n",
      " 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0013132 0.0006566 0.0013132 0.0006566\n",
      " 0.0006566 0.0006566 0.0006566 0.0013132 0.0006566 0.0013132 0.0006566\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566 0.0013132\n",
      " 0.0006566 0.0013132 0.0013132 0.0006566 0.0013132 0.0013132 0.0006566\n",
      " 0.0013132 0.0013132 0.0013132 0.0006566 0.0006566 0.0006566]\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "classifier.fit(X=train_set, y=train_labels)\n",
    "alphas = []\n",
    "classifiers = []\n",
    "for iteration in range(number_of_iterations):\n",
    "    model = train_model(classifier, weights)\n",
    "    weights = set_new_weights(model)\n",
    "    classifiers.append(model)\n",
    "\n",
    "print(weights)\n",
    "\n",
    "\n",
    "validate_x, validate_label = generate_data(1, dimension, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the validation data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_x, validate_label = generate_data(1, dimension, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the prediction code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(x):\n",
    "    predictions = []\n",
    "    for i in range(len(classifiers)):\n",
    "        predicted = classifiers[i].predict(x)\n",
    "        predictions.append(int(predicted))\n",
    "    counts = np.bincount(predictions)\n",
    "    print(predictions) #line NOT necessary, just for checking\n",
    "    return np.argmax(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "prediction = get_prediction(validate_x)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
